{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**1. Setting Up Your Development Environment**\n",
    "\n",
    "*   **Project Creation:** Start by creating a new project in an IDE like PyCharm,vscode. This helps organize your files and manage dependencies.\n",
    "*   **Package Installation**:  You need two primary libraries:\n",
    "    *   **opencv-python (cv2):** This library provides tools for computer vision tasks like capturing video, reading image frames, and drawing shapes and text on images.\n",
    "    *   **mediapipe (mp):**  This library, developed by Google, contains pre-built machine learning models for tasks like hand tracking. You'll use it to detect hands and their landmarks. Install these packages using your IDE's package manager, or with pip in the terminal, using the command `pip install opencv-python mediapipe`.\n",
    "\n",
    "**2. Basic Webcam Access**\n",
    "\n",
    "*   **Import Libraries:** Bring in the necessary libraries:\n",
    "    *   `import cv2`: For video and image processing.\n",
    "    *  `import mediapipe as mp`: To access MediaPipe's functionalities.\n",
    "    *   `import time`: To measure the frame rate (FPS).\n",
    "*   **VideoCapture Object:**  Create a `cv2.VideoCapture()` object to access your webcam. The argument `0` or `1` typically specifies the webcam you want to use.\n",
    "*   **Reading Frames:** The `cap.read()` function reads frames from the webcam. It returns two values: a boolean that indicates if the frame was successfully read and the frame itself as an image.\n",
    "*   **Displaying Video:** Use `cv2.imshow()` to display the video feed in a window. The first parameter is the window name, and the second is the image frame to be displayed.\n",
    "*   **Closing the Window:**  Use `cv2.waitKey(1)` to wait for a key press. Check if the pressed key is 'q' or any other key you choose to close the window.\n",
    "\n",
    "**3. Hand Detection with MediaPipe**\n",
    "\n",
    "*   **Creating a Hands Object:** Instantiate a `mp.solutions.hands.Hands()` object to use MediaPipe’s hand tracking model.\n",
    "    *   This object is a tool that uses machine learning to find hands in the video and locate 21 specific landmark points on each hand.\n",
    "    *   The `Hands()` class has parameters that control how the model works, including:\n",
    "        *   `static_image_mode`: When set to false, the model will do detection only when tracking confidence is low, improving speed. Setting it to `true` forces detection in every frame, which will slow down the process.\n",
    "        *   `max_num_hands`: The maximum number of hands to detect.\n",
    "        *   `min_detection_confidence`: The minimum confidence for detection to occur.\n",
    "        *   `min_tracking_confidence`: The minimum confidence required to continue tracking.\n",
    "    *   You can use the default values of these parameters, and do not need to specify them during initialization.\n",
    "*   **Image Conversion:** MediaPipe's model uses RGB format, but OpenCV uses BGR. Convert the image using `cv2.cvtColor(image, cv2.COLOR_BGR2RGB)`.\n",
    "*   **Processing the Image:** Use the `process()` method of the `hands` object to get the hand tracking results, e.g., `results = hands.process(image_rgb)`.\n",
    "\n",
    "**4. Visualizing Hand Landmarks**\n",
    "\n",
    "*   **Checking for Detections:**  Confirm that hands have been detected by checking if `results.multi_hand_landmarks` is not `None`.\n",
    "*   **Iterating Through Hands:** If hands are detected, loop through the `results.multi_hand_landmarks` to get the landmarks of each detected hand.\n",
    "*   **Drawing Utilities:** Create an object for drawing using `mp.solutions.drawing_utils`, which contains methods for drawing landmarks and the connections between them.\n",
    "*   **Drawing Landmarks and Connections:**  Use the `draw_landmarks()` method from `mp_draw` object to draw the landmarks and their connections on the original BGR image. You will pass in the image, the landmarks for one hand, and the hand connections from `mp.solutions.hands.HAND_CONNECTIONS` to the `draw_landmarks` method.\n",
    "\n",
    "**5. Calculating and Displaying FPS**\n",
    "\n",
    "*   **Initializing Time Variables:** Set `previous_time` and `current_time` to zero before starting the video loop.\n",
    "*  **Getting Current Time:** Inside the video loop, use `current_time = time.time()` to get the current time in seconds.\n",
    "*   **Calculating FPS:** Calculate frames per second using the formula `fps = 1 / (current_time - previous_time)`.\n",
    "*   **Updating `previous_time`:** Update `previous_time` with the current time so that the difference of the time is calculated between subsequent frames, `previous_time = current_time`.\n",
    "*  **Displaying FPS:** Use `cv2.putText()` to display the calculated FPS on the image. This function takes the image, the text to display, the position of the text, the font, scale, color and thickness as arguments.\n",
    "\n",
    "**6. Extracting Landmark Positions**\n",
    "\n",
    "*   **Iterating Through Landmarks:** When hands are detected, loop through the landmarks for each hand using `enumerate()`. This gives you both the ID (index number) of the landmark and its landmark object.\n",
    "*   **Pixel Coordinates:**  The landmark coordinates are given as ratios of the image dimensions (between 0 and 1). To get pixel coordinates, multiply the x and y values by the width and height of the image.  Convert these values to integers since pixel locations need to be integers.\n",
    "*   **Storing Coordinates:** You can store the extracted ID, x-coordinate, and y-coordinate values for each landmark in a list so that they can be used for other tasks.\n",
    "\n",
    "**7. Highlighting Specific Landmarks**\n",
    "\n",
    "*   **Conditional Drawing:**  Use an `if` statement to check the ID of the landmark you want to highlight.\n",
    "*   **Drawing a Circle:** Use `cv2.circle()` to draw a circle at the calculated pixel coordinates of the selected landmark.\n",
    "*   **Customizing the Circle:** Customize the circle’s position, radius, color, and fill using the parameters of the `cv2.circle()` function.\n",
    "\n",
    "**8. Creating a Hand Tracking Module (Class)**\n",
    "\n",
    "*   **New File:** Create a new Python file named `hand_tracking_module.py`.\n",
    "*   **Class Creation:** Create a class called `handDetector` to organize the hand tracking functionality.\n",
    "*   **`__init__` Method:** This is the constructor of your class. It initializes the hand tracking parameters (`mode`, `max_hands`, `detectionCon`, and `trackCon`) and also creates the media pipe hands object using these parameters.\n",
    "*   **`findHands` Method:** Create a `findHands` method that takes an image and a draw flag as input. This method performs the actual hand detection using MediaPipe and draws the landmarks on the image if the draw flag is set to true.\n",
    "*  **`findPosition` Method**:\n",
    "    *   Create a `findPosition` method that takes the image, hand number and draw flag as input.\n",
    "    *    This method is responsible for extracting the positions of the hand landmarks and returning them as a list.\n",
    "    *   First, create an empty list called `lmList` that you will use to store the landmark information.\n",
    "    *   Check that the results contain detected hand landmarks. If hands are detected, get the landmarks for the hand indicated by the `hand number` parameter.\n",
    "    *   Loop through the landmarks, extract their ID, x, and y pixel coordinates, and append them to the `lmList`.\n",
    "    *   Optionally draw landmarks on the image based on the value of the `draw` flag.\n",
    "    *   Return the `lmList` which now contains the information on the hand landmarks.\n",
    "*  **Dummy Code:** Use `if __name__ == '__main__':` to include dummy code that demonstrates how to use the module and its capabilities. This includes:\n",
    "    *   A `main` function that encapsulates the main functionality of the dummy code.\n",
    "    *   The while loop for video capture, reading and processing frames, and displaying the video.\n",
    "    *  Creating an instance of the handDetector class and call the method `findHands` and `findPosition` to perform detection and get landmark information.\n",
    "\n",
    "**9. Using the Module in Another Project**\n",
    "\n",
    "*   **Import:** In your new project, import the hand tracking module as `htm` using  `import hand_tracking_module as htm`.\n",
    "*   **Create Instance:** Create an instance of the `handDetector` class from your imported module `htm.handDetector()`.\n",
    "*  **Call Methods**:\n",
    "    *   Call the `findHands` method to process the video feed, draw the landmarks and display the video.\n",
    "    *   Call the `findPosition` method to retrieve the landmark positions.\n",
    "    * You can access the position of a particular landmark by indexing the list returned by `findPosition`.\n",
    "*   **Optional Drawing:** You can enable or disable the drawing of the landmarks by setting the draw parameter to `True` or `False` respectively in the `findHands` and the `findPosition` methods.\n",
    "\n",
    "This detailed explanation should give you a better understanding of each step involved in building the hand tracking module. Remember to refer back to the source code for specific syntax and implementation details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anotherway\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a hand tracking module using OpenCV and MediaPipe, follow these steps:\n",
    "\n",
    "**1. Set up the development environment:**\n",
    "*   Create a new project in your preferred Python IDE, such as PyCharm,vscode.\n",
    "*   Install the required packages: **opencv-python** and **mediapipe**. This can typically be done through the IDE's package installer or using pip in the terminal.\n",
    "\n",
    "**2. Write the basic code for webcam access:**\n",
    "*   Import the necessary libraries: `cv2`, `mediapipe as mp`, and `time`.\n",
    "*   Create a video capture object using `cv2.VideoCapture(0 or 1)`, where 0 or 1 is the index of the webcam.\n",
    "*   Read frames from the webcam using `cap.read()`.\n",
    "*   Display the video feed using `cv2.imshow()`.\n",
    "*   Implement a way to close the window with a key press, such as 'q'.\n",
    "\n",
    "**3. Implement hand detection using MediaPipe:**\n",
    "*   Create a MediaPipe hands object using `mp.solutions.hands.Hands()`.\n",
    "    *   This object is what will perform the hand detection and landmarking using the MediaPipe models.\n",
    "    *   The `Hands()` class has parameters such as `static_image_mode`, `max_num_hands`, `min_detection_confidence`, and `min_tracking_confidence`.\n",
    "    *   The default values for these parameters are already set, so they can be skipped during initialization.\n",
    "*   Convert the image from BGR (OpenCV's default) to RGB using `cv2.cvtColor(image, cv2.COLOR_BGR2RGB)` because the MediaPipe model expects RGB images.\n",
    "*   Process the RGB image using the hands object's `process()` method to get the results, e.g., `results = hands.process(image_rgb)`.\n",
    "\n",
    "**4. Extract and visualize hand landmarks:**\n",
    "*   Check if any hands were detected using `results.multi_hand_landmarks`.\n",
    "*   If hands are detected, iterate through each hand's landmarks using a for loop.\n",
    "*   Create an object for drawing utilities using `mp.solutions.drawing_utils`, which provides methods for drawing the landmarks and connections.\n",
    "*   Draw the hand landmarks and connections on the original BGR image using `mp_draw.draw_landmarks(image, hand_lms, mp_hands.HAND_CONNECTIONS)`.\n",
    "\n",
    "**5. Calculate and display the frame rate (FPS):**\n",
    "*   Initialize `previous_time` and `current_time` variables to 0.\n",
    "*   Inside the loop, calculate the current time using `time.time()`.\n",
    "*   Calculate FPS using the formula `1 / (current_time - previous_time)`.\n",
    "*   Update `previous_time` with the `current_time` for the next calculation.\n",
    "*   Display the FPS on the image using `cv2.putText()`.\n",
    "\n",
    "**6. Extract landmark positions:**\n",
    "*   Iterate through the landmarks of each hand, using `enumerate()` to get both the index (id) and the landmark.\n",
    "*   The landmark coordinates are given as ratios of the image dimensions, so multiply the x and y values by the image's width and height to get pixel coordinates.\n",
    "*   Convert the x and y pixel coordinates to integers.\n",
    "\n",
    "**7. Draw a circle on a specific landmark:**\n",
    "*   To highlight a particular landmark, use `cv2.circle()` to draw a circle at the specified coordinates.\n",
    "*   Customize the circle’s position, radius, color, and fill using the parameters of `cv2.circle()`.\n",
    "    *   You can select the landmark to highlight by checking its id using an if condition.\n",
    "    *   For example, id 0 is the wrist and id 4 is the tip of the thumb.\n",
    "\n",
    "**8. Create a Hand Tracking Module (Class):**\n",
    "*   Create a new file called `hand_tracking_module.py`.\n",
    "*   Create a class called `handDetector` to encapsulate all the hand tracking functionalities.\n",
    "*   Define an `__init__` method to initialize the hand tracking parameters such as `mode`, `max_hands`, `detectionCon`, and `trackCon` as well as the media pipe hands object.\n",
    "*   Create a method `findHands` to handle the hand detection process, which will include image conversion, processing with MediaPipe, and drawing landmarks. This method should take an image and an optional draw flag as input.\n",
    "*   Create a method `findPosition` that extracts the landmark positions and returns them as a list.\n",
    "    *   This method will also have the option to draw or not draw the landmarks, depending on the value of the `draw` parameter.\n",
    "    *  The `findPosition` method iterates over the detected hands and landmarks to extract the pixel coordinates of each landmark.\n",
    "    *  It appends these coordinates and their ID to a list which is then returned.\n",
    "*   Use a `if __name__ == '__main__':` block to include a dummy code to showcase what the module can do.\n",
    "    *  In this block, create a `main()` function that contains the while loop for webcam access.\n",
    "    *  Create an instance of the `handDetector` class.\n",
    "    *  Call the `findHands` method to perform hand detection and display.\n",
    "    *  Call the `findPosition` method to get the coordinates of the hand landmarks.\n",
    "\n",
    "**9. Use the module in a separate project:**\n",
    "*   Import the hand tracking module into another python script using `import hand_tracking_module as htm`.\n",
    "*   Create an instance of the `handDetector` class using `htm.handDetector()`.\n",
    "*   Call the methods of this class to process the video feed and get the hand landmark positions.\n",
    "*   You can get the values of a specific landmark by indexing the list returned by `findPosition`.\n",
    "*   You can also choose to not draw the landmarks by setting the draw parameter to false.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
